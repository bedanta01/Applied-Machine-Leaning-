{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import string\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score \n",
    "from sklearn.naive_bayes import GaussianNB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6760)\t0.0860370549013\n",
      "  (0, 12315)\t0.151488428768\n",
      "  (0, 16130)\t0.127360707989\n",
      "  (0, 8597)\t0.0971013190859\n",
      "  (0, 4431)\t0.248179637506\n",
      "  (0, 1975)\t0.209561378978\n",
      "  (0, 3639)\t0.092451288572\n",
      "  (0, 875)\t0.165849237064\n",
      "  (0, 11261)\t0.139029275508\n",
      "  (0, 12725)\t0.162815364045\n",
      "  (0, 15394)\t0.17462966428\n",
      "  (0, 12132)\t0.201589111257\n",
      "  (0, 15906)\t0.254013554514\n",
      "  (0, 945)\t0.172625825517\n",
      "  (0, 8227)\t0.125098907138\n",
      "  (0, 12131)\t0.128560421774\n",
      "  (0, 10115)\t0.157385921098\n",
      "  (0, 4879)\t0.110746753245\n",
      "  (0, 14806)\t0.174660328504\n",
      "  (0, 16504)\t0.0884374829275\n",
      "  (0, 9748)\t0.0962734078134\n",
      "  (0, 14676)\t0.0920950550392\n",
      "  (0, 3780)\t0.103659264078\n",
      "  (0, 4534)\t0.0931769774575\n",
      "  (0, 4643)\t0.137015083336\n",
      "  :\t:\n",
      "  (699, 11700)\t0.0890461257572\n",
      "  (699, 11171)\t0.0890461257572\n",
      "  (699, 15561)\t0.0890461257572\n",
      "  (699, 618)\t0.0890461257572\n",
      "  (699, 9682)\t0.0890461257572\n",
      "  (699, 9072)\t0.0890461257572\n",
      "  (699, 8820)\t0.0890461257572\n",
      "  (699, 18648)\t0.0890461257572\n",
      "  (699, 16585)\t0.0890461257572\n",
      "  (699, 11189)\t0.0890461257572\n",
      "  (699, 9058)\t0.0890461257572\n",
      "  (699, 11187)\t0.0890461257572\n",
      "  (699, 8337)\t0.0890461257572\n",
      "  (699, 8804)\t0.0890461257572\n",
      "  (699, 18836)\t0.0890461257572\n",
      "  (699, 11704)\t0.0890461257572\n",
      "  (699, 8433)\t0.0890461257572\n",
      "  (699, 1270)\t0.0890461257572\n",
      "  (699, 6268)\t0.0890461257572\n",
      "  (699, 700)\t0.0890461257572\n",
      "  (699, 12783)\t0.0890461257572\n",
      "  (699, 4940)\t0.0890461257572\n",
      "  (699, 6728)\t0.0890461257572\n",
      "  (699, 14195)\t0.0890461257572\n",
      "  (699, 3222)\t0.0890461257572\n"
     ]
    }
   ],
   "source": [
    "train_spam_folder = os.listdir(\"EmailsData\\\\spam-train\")\n",
    "train_non_spam_folder = os.listdir(\"EmailsData\\\\nonspam-train\")\n",
    "\n",
    "test_spam_folder = os.listdir(\"EmailsData\\\\spam-test\")\n",
    "test_non_spam_folder = os.listdir(\"EmailsData\\\\nonspam-test\")\n",
    "\n",
    "train_email_data = []\n",
    "train_label = []\n",
    "\n",
    "test_email_data = []\n",
    "test_label = []\n",
    "\n",
    "spam_token_dict = {}\n",
    "\n",
    "vect = TfidfVectorizer(sublinear_tf=True, max_df=0.5, analyzer='word', \n",
    "           stop_words='english')\n",
    "\n",
    "train_words = []\n",
    "\n",
    "for file in train_spam_folder:\n",
    "    file_path = os.path.join(\"EmailsData\\\\spam-train\",file)\n",
    "    with open(file_path) as f:\n",
    "        text = f.read()\n",
    "        train_email_data.append(text)\n",
    "        train_label.append(1)\n",
    "\n",
    "for file in train_non_spam_folder:\n",
    "    file_path = os.path.join(\"EmailsData\\\\nonspam-train\",file)\n",
    "    with open(file_path) as f:\n",
    "        text = f.read()\n",
    "        train_email_data.append(text)\n",
    "        train_label.append(0)\n",
    "\n",
    "        \n",
    "        \n",
    "for file in test_spam_folder:\n",
    "    file_path = os.path.join(\"EmailsData\\\\spam-test\",file)\n",
    "    with open(file_path) as f:\n",
    "        text = f.read()\n",
    "        test_email_data.append(text)\n",
    "        test_label.append(1)\n",
    "        \n",
    "for file in test_non_spam_folder:\n",
    "    file_path = os.path.join(\"EmailsData\\\\nonspam-test\",file)\n",
    "    with open(file_path) as f:\n",
    "        text = f.read()\n",
    "        test_email_data.append(text)\n",
    "        test_label.append(0)\n",
    "        \n",
    "x_train = vect.fit_transform(train_email_data)\n",
    "x_test = vect.transform(test_email_data)\n",
    "\n",
    "#print(len(spam_token_dict))\n",
    "print (x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vector = vect.fit_transform(train_email_data)\n",
    "\n",
    "select_k_best = SelectKBest(mutual_info_classif,k=50)\n",
    "train_spam = select_k_best.fit_transform(tf_vector,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['prohibit', 'prospect', 'pyramid', 'questions', 'random',\n",
       "       'recognize', 'rental', 'responsive', 'rewrite', 'ring', 'riskfree',\n",
       "       'robbie', 'safemail', 'september', 'sick', 'singles', 'skeptic',\n",
       "       'skip', 'solicitation', 'specials', 'spider', 'stage', 'steal',\n",
       "       'storage', 'straightforward', 'subscription', 'suggestion',\n",
       "       'superior', 'surround', 'survey', 'sweepstakes', 'technician',\n",
       "       'tel', 'texa', 'thoma', 'thompson', 'tour', 'trace', 'transaction',\n",
       "       'unit', 'urls', 'vega', 'vist', 'void', 'volumes', 'walk',\n",
       "       'wealthiest', 'whatso', 'windows', 'yearold'],\n",
       "      dtype='<U74')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(vect.get_feature_names())[select_k_best.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Naive bayes accuracy:  100.0\n",
      "Confusion-Matrix: \n",
      " [[127   3]\n",
      " [  4 126]]\n",
      "F1-score:  1.0\n",
      "ROC-AUC:  0.973076923077\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb = GaussianNB()\n",
    "\n",
    "gaussian_nb.fit(x_train.toarray(), train_label)### fit the tfidvectorized matrix\n",
    "pred = gaussian_nb.predict(x_test.toarray())### predict the test data\n",
    "acc = accuracy_score(test_label, pred)### calculate accuracy\n",
    "print (\"sklearn Naive bayes accuracy: \", round(acc)*100.0)\n",
    "\n",
    "print (\"Confusion-Matrix: \\n\", confusion_matrix(test_label, pred))\n",
    "\n",
    "print (\"F1-score: \", round(f1_score(test_label, pred)))\n",
    "\n",
    "print (\"ROC-AUC: \", roc_auc_score(test_label, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
